{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ece95bd3-5f94-486c-9014-53ca1afe7b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting physical preprocessing to resize images to (96, 96)...\n",
      "------------------------------------------------------------\n",
      "Preprocessing complete! Took 38.17 seconds.\n",
      "Total images processed and saved: 9600\n",
      "New dataset saved at: 'Fingerprint_Preprocessed_Dataset'\n",
      "This dataset is now ready for direct loading into any ML framework.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "# --- Configuration ---\n",
    "# Root directory containing the 'train' and 'test' folders (Output from Data_split.py)\n",
    "SPLIT_ROOT_DIR = r\"Fingerprint_Split_Dataset\"\n",
    "\n",
    "# New directory where the fully preprocessed (resized) images will be saved\n",
    "PREPROCESSED_ROOT_DIR = r\"Fingerprint_Preprocessed_Dataset\"\n",
    "\n",
    "# Target size for all images\n",
    "TARGET_SIZE = (96, 96) \n",
    "\n",
    "# File extensions to look for\n",
    "IMAGE_EXTENSIONS = ('.tif', '.png', '.jpg', '.jpeg')\n",
    "# ---------------------\n",
    "\n",
    "def preprocess_and_save_data(split_dir, dest_dir, target_size, extensions):\n",
    "    \"\"\"\n",
    "    Traverses the split dataset, resizes each image, converts to grayscale, \n",
    "    and saves it to a new, parallel directory structure.\n",
    "    \"\"\"\n",
    "    print(f\"Starting physical preprocessing to resize images to {target_size}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    Path(dest_dir).mkdir(parents=True, exist_ok=True)\n",
    "    processed_count = 0\n",
    "    \n",
    "    # os.walk is used to traverse the directory structure recursively\n",
    "    for root, dirs, files in os.walk(split_dir):\n",
    "        # Determine the relative path from the split root to the current directory (root)\n",
    "        # This helps us replicate the 'train/person_id' structure\n",
    "        relative_path = Path(root).relative_to(split_dir)\n",
    "        \n",
    "        # Create the corresponding directory in the new preprocessed path\n",
    "        target_dir = Path(dest_dir) / relative_path\n",
    "        target_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        for filename in files:\n",
    "            # Check for valid image extensions\n",
    "            if filename.lower().endswith(extensions):\n",
    "                source_path = Path(root) / filename\n",
    "                dest_path = target_dir / filename\n",
    "                \n",
    "                try:\n",
    "                    # 1. Load the image\n",
    "                    img = Image.open(source_path)\n",
    "                    \n",
    "                    # 2. Convert to Grayscale (if not already)\n",
    "                    # CNNs for fingerprints usually prefer a single channel\n",
    "                    if img.mode != 'L':\n",
    "                        img = img.convert('L') \n",
    "                        \n",
    "                    # 3. Resize the image (using BICUBIC interpolation for quality)\n",
    "                    resized_img = img.resize(target_size, Image.Resampling.BICUBIC)\n",
    "                    \n",
    "                    # 4. Save the preprocessed image to the new location\n",
    "                    resized_img.save(dest_path)\n",
    "                    \n",
    "                    processed_count += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {source_path}: {e}\")\n",
    "            \n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Preprocessing complete! Took {end_time - start_time:.2f} seconds.\")\n",
    "    print(f\"Total images processed and saved: {processed_count}\")\n",
    "    print(f\"New dataset saved at: '{PREPROCESSED_ROOT_DIR}'\")\n",
    "    print(\"This dataset is now ready for direct loading into any ML framework.\")\n",
    "\n",
    "# Run the function\n",
    "preprocess_and_save_data(SPLIT_ROOT_DIR, PREPROCESSED_ROOT_DIR, TARGET_SIZE, IMAGE_EXTENSIONS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec04868b-ed2d-4fe9-9832-013c9e87f159",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
